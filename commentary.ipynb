{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import * \n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import random\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6741\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs()\n",
    "\n",
    "maxLen = 50\n",
    "\n",
    "X, Y = read_csv(word_to_index, 10, maxLen)\n",
    "# print(X.shape)\n",
    "# Z = list(zip(X,Y))\n",
    "# random.shuffle(Z)\n",
    "\n",
    "# X, Y = zip(*Z)\n",
    "# X, Y = list(X), list(Y)\n",
    "for i in range(len(Y)):\n",
    "    Y[i] -= 1\n",
    "X_length = len(X)\n",
    "max_mult = X_length//256\n",
    "print(X_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6741,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# for sentence in X:\n",
    "#     sentence_to_words = sentence.lower().split(\".\")\n",
    "#     sentence_to_words = sentence_to_words[0].split()\n",
    "#     list_len.append(len(sentence_to_words))\n",
    "# print(list_len[:10])\n",
    "# print(max(list_len))\n",
    "# print(sum(list_len) / len(list_len))\n",
    "# list_triee = sorted(list_len)\n",
    "# for i in range(10):\n",
    "#     print(list_triee[i * len(list_triee)//10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train = X[0:256*(max_mult - 2)], Y[0:256*(max_mult - 2)]\n",
    "X_test, Y_test = X[256*(max_mult - 2):256*(max_mult - 1)], Y[256*(max_mult - 2):256*(max_mult - 1)]\n",
    "X_valid, Y_valid = X[256*(max_mult - 1):256*max_mult], Y[256*(max_mult - 1):256*max_mult]\n",
    "\n",
    "Y_train_oh = convert_to_oh(Y_train, C = 5)\n",
    "Y_test_oh = convert_to_oh(Y_test, C = 5)\n",
    "Y_valid_oh = convert_to_oh(Y_valid, C = 5)\n",
    "\n",
    "# X_train, Y_train = read_csv2('data/train_emoji.csv')\n",
    "# X_test, Y_test = read_csv2('data/tesss.csv')\n",
    "# X_valid, Y_valid = X_test, Y_test\n",
    "# Y_train_oh = convert_to_oh(Y_train, C = 5)\n",
    "# Y_test_oh = convert_to_oh(Y_test, C = 5)\n",
    "# Y_valid_oh = convert_to_oh(Y_test, C = 5)\n",
    "\n",
    "print( len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84800e9d328f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(X_test[i], Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "\n",
    "        sentence_to_words = X[i].lower().split(\".\")\n",
    "        sentence_to_words = sentence_to_words[0].split()\n",
    "        j = 0\n",
    "\n",
    "        for w in sentence_to_words:\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j += 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol. test.' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices =\n",
      " [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol. test.\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences max length:  50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# m = X.shape[0]\n",
    "# maxLen = 0\n",
    "# for i in range(m):\n",
    "#     sentence_to_words = X[i].lower().split(\".\")\n",
    "#     sentence_to_words = sentence_to_words[0].split()\n",
    "#     if len(sentence_to_words) > maxLen:\n",
    "#         maxLen = len(sentence_to_words)\n",
    "print(\"Sentences max length: \", maxLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentary(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the commentary model's graph.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences= True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences= False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 5 units\n",
    "    X = Dense(5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commentary((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compile......\n"
     ]
    }
   ],
   "source": [
    "print(\"Model compile......\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in X_train:\n",
    "#     print(len(x))\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit......\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3138 - accuracy: 0.4255\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1839 - accuracy: 0.4696\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1621 - accuracy: 0.4696\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1191 - accuracy: 0.4982\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0950 - accuracy: 0.4930\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0663 - accuracy: 0.5282\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0398 - accuracy: 0.5360\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0237 - accuracy: 0.5373\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9890 - accuracy: 0.5549\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9741 - accuracy: 0.5747\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9528 - accuracy: 0.5879\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9393 - accuracy: 0.5902\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9297 - accuracy: 0.5962\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9009 - accuracy: 0.6128\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8777 - accuracy: 0.6214\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8597 - accuracy: 0.6263\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8357 - accuracy: 0.6494\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8029 - accuracy: 0.6628\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7791 - accuracy: 0.6777\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7412 - accuracy: 0.6912\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7196 - accuracy: 0.7021\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7346 - accuracy: 0.6930\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6724 - accuracy: 0.7197\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6533 - accuracy: 0.7344\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6200 - accuracy: 0.7542\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5929 - accuracy: 0.7622\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5684 - accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5486 - accuracy: 0.7860\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5102 - accuracy: 0.8022\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4829 - accuracy: 0.8133\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.8385\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4465 - accuracy: 0.8356\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.8372\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3856 - accuracy: 0.8605\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.8791\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.3739 - accuracy: 0.8665\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3082 - accuracy: 0.8936\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2814 - accuracy: 0.9028\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2857 - accuracy: 0.9002\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2509 - accuracy: 0.9220\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2703 - accuracy: 0.9106\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2609 - accuracy: 0.9119\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2013 - accuracy: 0.9347\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2131 - accuracy: 0.9318\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9429\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1905 - accuracy: 0.9398\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1729 - accuracy: 0.9460\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2266 - accuracy: 0.9300\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1685 - accuracy: 0.9429\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9546\n",
      "End of fitting......\n"
     ]
    }
   ],
   "source": [
    "print(\"Model fit......\")\n",
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 64, shuffle=True)\n",
    "print(\"End of fitting......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3917 - accuracy: 0.4844\n",
      "\n",
      "Test accuracy =  0.484375\n"
     ]
    }
   ],
   "source": [
    "X_valid_indices = sentences_to_indices(X_valid, word_to_index, max_len = maxLen)\n",
    "loss, acc = model.evaluate(X_valid_indices, Y_valid_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family run personal nice area , older hotel basic 1 night stay , result having stop singapore way locations traveling stayed south east asia hotel 1 stays hotel bencoolen review property stay \n",
      "游비游비游비游비游비 =/= 游눜游눜游눜\n",
      "home florence arrived long car trip angela awaiting , immediately showed room gave quick thorough instructions , able relax spacious cozy spotless room no delay , later directed neighborhood restaurant captured soul tuscany , did not use car stay minibus takes ponte vecchio block hotel gets minutes \n",
      "游비 =/= 游눜游눜游눜游눜游눜\n",
      "gorgeous resort beautiful , grounds amazing , complaint not best single travelers inclusive n ' t area singles , small casino resort open night , bars , beach pools nice , staff moderately friendly helpful not overly ,  \n",
      "游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "just like dumb blonde , wife stayed ocean royal service suite april 21 28th \n",
      "游비游비游비游비游비 =/= 游눜游눜\n",
      "special celebration husband adult children just got week , stayed thanksgiving weekend celebrate 50th birthday , resort gorgeous , no roaches place clean , no problems check-in service safe did not work , arrived , security came immediately fixed , food ok \n",
      "游비 =/= 游눜游눜游눜游눜\n",
      "not expected , stayed ocean blue golf beach resort feb \n",
      "游비游비游비游비 =/= 游눜游눜\n",
      "perfect clean friendly helpful staff decent breakfast comfy bed cant fault hotel quite picky ,  \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "loved did n ' t use bug spray , loved resort , suite lovely lay bed look ocean sit patio plunge pool relax , taken hint insect repellent room spray closet biting insects vicious , tend mosquito magnet multiple bites did not spray thoroughly repeatedly day evening \n",
      "游비游비 =/= 游눜游눜游눜游눜\n",
      "totally worth price line short distance silver line makes totally worth cheaper price hotel , forget previous babies posted , unless trouble walking perfect , homework subway ahead time time , spend 15 airport weekly pass staying days , totally worth plus convenience factor \n",
      "游비游비 =/= 游눜游눜游눜游눜\n",
      "just okay stayed hotel convention , live boston thought fun stay hotel , good news , bed extremely comfortable , flat tv nice , loved contemporary decor room , nice city / water view \n",
      "游비游비游비游비 =/= 游눜游눜\n",
      "lousy desk service stayed friend biz trip 2 nites 21-23 april \n",
      "游비游비游비游비 =/= 游눜\n",
      "feel renewed husband just returned 7 night stay renew hotel \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "nice unique simple staff friendly did accommodate , location perfect close beach food , really like borrow beach equipment free \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "dont waste money , boyfriend thought picked maybe best hotels dallas stay 21st birthday night sadly wrong \n",
      "游비游비游비游비游비 =/= 游눜\n",
      "disappointing booked hotel based reviews read disappointed , booked superior rooms paying price , couple given room just big house double bed , single travelling companion given single room feet square floor space shower flooded room used \n",
      "游비游비游비 =/= 游눜\n",
      "not typical amsterdam hotel real hotel amsterdam city centre , really impressed , previous reviews say , complaint walk 10 mins station catch tram hit cafes bars , little immediate area access city centre obstructed railway ,  \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "anniversary memorable wife celebrated 15th wedding anniversary blue moon hotel lower east new york city june 19th 2008 \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "little gem great location , looking good hotel 100 euros night downtown barcelona , terrific location quiet local area brisk 20 min walk plaza catalunya \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "not centre not far worth walk , absolutely no complaints hotel , receptionists helpful rooms clean included free minibar good facilities excellent value money rate paid room night , breakfast extra 3 \n",
      "游비游비游비 =/= 游눜游눜游눜游눜游눜\n",
      "ca n ' t wait , unhappy vacationers , background husband late 20 early 30 travel possible no kids hampton roads virginia , stayed riu yucatan mexican riveria familiar riu chain \n",
      "游비 =/= 游눜游눜游눜游눜\n",
      "miss match =  20 / 256\n",
      "one star difference =  93 / 256\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "miss_match = 0\n",
    "one_difference = 0\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(abs(num - Y_test[i]) >= 2):\n",
    "        print(X_test[i])\n",
    "        print(emoji.emojize(':orange_heart:')*(num+1), '=/=',emoji.emojize(':green_heart:')*(Y_test[i]+1))\n",
    "        miss_match = miss_match +1\n",
    "    elif abs(num - Y_test[i]) == 1:\n",
    "        one_difference +=1\n",
    "print('miss match = ' , miss_match,  \"/\" , len(X_test))\n",
    "print('one star difference = ' , one_difference,  \"/\" , len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss match =  20 / 256 ===> 7.8125 %\n",
      "one star difference =  93 / 256 ===> 36.328125 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('miss match = ' , miss_match,  \"/\" , len(X_test), '===>', (miss_match/len(X_test)*100), \"%\")\n",
    "print('one star difference = ' , one_difference,  \"/\" , len(X_test), '===>', (one_difference/len(X_test)*100), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
