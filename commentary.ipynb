{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.8 64-bit",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "40a72caf6fa46f53aa7f5b366fbd5b98b2736726cc2be7465f0404892e27bcbd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import * \n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import random\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6741\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs()\n",
    "\n",
    "maxLen = 50\n",
    "\n",
    "X, Y = read_csv(word_to_index, 10, maxLen)\n",
    "# print(X.shape)\n",
    "# Z = list(zip(X,Y))\n",
    "# random.shuffle(Z)\n",
    "\n",
    "# X, Y = zip(*Z)\n",
    "# X, Y = list(X), list(Y)\n",
    "for i in range(len(Y)):\n",
    "    Y[i] -= 1\n",
    "X_length = len(X)\n",
    "max_mult = X_length//256\n",
    "print(X_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6741,)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X.shape\n",
    "# for sentence in X:\n",
    "#     sentence_to_words = sentence.lower().split(\".\")\n",
    "#     sentence_to_words = sentence_to_words[0].split()\n",
    "#     list_len.append(len(sentence_to_words))\n",
    "# print(list_len[:10])\n",
    "# print(max(list_len))\n",
    "# print(sum(list_len) / len(list_len))\n",
    "# list_triee = sorted(list_len)\n",
    "# for i in range(10):\n",
    "#     print(list_triee[i * len(list_triee)//10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train = X[0:256*(max_mult - 2)], Y[0:256*(max_mult - 2)]\n",
    "X_test, Y_test = X[256*(max_mult - 2):256*(max_mult - 1)], Y[256*(max_mult - 2):256*(max_mult - 1)]\n",
    "X_valid, Y_valid = X[256*(max_mult - 1):256*max_mult], Y[256*(max_mult - 1):256*max_mult]\n",
    "\n",
    "Y_train_oh = convert_to_oh(Y_train, C = 5)\n",
    "Y_test_oh = convert_to_oh(Y_test, C = 5)\n",
    "Y_valid_oh = convert_to_oh(Y_valid, C = 5)\n",
    "\n",
    "# X_train, Y_train = read_csv2('data/train_emoji.csv')\n",
    "# X_test, Y_test = read_csv2('data/tesss.csv')\n",
    "# X_valid, Y_valid = X_test, Y_test\n",
    "# Y_train_oh = convert_to_oh(Y_train, C = 5)\n",
    "# Y_test_oh = convert_to_oh(Y_test, C = 5)\n",
    "# Y_valid_oh = convert_to_oh(Y_test, C = 5)\n",
    "\n",
    "print( len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "beautiful family resort just returned week christmas holiday family 9 ranging age 12 64  4\nexcellent value money returned majestic week like review tripadvisor reviews useful deciding hotel to  4\nmixed rating property quite tough outstanding poor rating various reasons , buildings pools spa beach outstanding  2\nmajestic colonial just returned trip stayed majestic july 30 june 8  3\nnot ready visitors place wide berth months year not ready offer 5 star service fact expecting large 5 star hotel want n ' t think place really offer 5 star experience lot growing pains lot learn customer satisfaction , wife spent dec  0\nfabulous hotel great hotel , rooms amazing large great views clean , service excellent , location good close subway ,   4\nperfect hotel just stayed week prince park tower tokyo hotel rate hotel excellent especially room rate paid euro , comparison year stayed ana hotel expensive did not offer quality  4\nfamily run personal nice area , older hotel basic 1 night stay , result having stop singapore way locations traveling stayed south east asia hotel 1 stays hotel bencoolen review property stay  2\npay booked hotel directly e-mail , reservation staff replied friendly helpful communications , actually staff friendly feels like family hotel  2\njust okay stay 1 night , make reservation internet price cheap good location , room bit small dimly lit old tv old ac bathroom clean sized , pay cash near bugis mrt , night food hawkers not far hotel , u pay budget hotel friendly staff ,   1\nlovely hotel 44 year old couple uk went dr iberostar punta cana 6 21 june 2008  3\ndreamed husband stayed gorgeous hotel 4 / 30 / 07 5 / 7 / 07  4\niberostar fantastic just returned trip dominican republic punta cana , best vacations on  4\nbeautiful relaxing resort husband stayed resort june 3 june 9 2006  3\nwonderful better expected stayed iberostar punta cana 27 june 3  4\nincredible place , stayed iberostar punta cana 5th 12th 2006 year anniversary , best beautiful vacation taken , dr beautiful country resort exactly , grounds resort incredible , plenty activities ages , n ' t understand site complain food delicious , food tasted different u  4\nca n ' t wait , not add regards resort , absolutely wonderful , november 26 december 3  4\nhighly recommended restaurant took close half space lobby personally thought quite odd  4\nwonderful hospitality thrilled stay beautifully restored villa , fair walk centre good 20 mins buses stop nearby , able leave hire car car park great bonus  3\nwonderful choice hotel accurately described good reviews lovely place outside city center , salient features conditioner worked not given italy hospitable staff , ca n ' t say good things hosts  4\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(X_test[i], Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "\n",
    "        sentence_to_words = X[i].lower().split(\".\")\n",
    "        sentence_to_words = sentence_to_words[0].split()\n",
    "        j = 0\n",
    "\n",
    "        for w in sentence_to_words:\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j += 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X1 = ['funny lol. test.' 'lets play baseball' 'food is ready for you']\nX1_indices =\n [[155345. 225122.      0.      0.      0.]\n [220930. 286375.  69714.      0.      0.]\n [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol. test.\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentences max length:  50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# m = X.shape[0]\n",
    "# maxLen = 0\n",
    "# for i in range(m):\n",
    "#     sentence_to_words = X[i].lower().split(\".\")\n",
    "#     sentence_to_words = sentence_to_words[0].split()\n",
    "#     if len(sentence_to_words) > maxLen:\n",
    "#         maxLen = len(sentence_to_words)\n",
    "print(\"Sentences max length: \", maxLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentary(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the commentary model's graph.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences= True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences= False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with 5 units\n",
    "    X = Dense(5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 50)]              0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 50, 50)            20000050  \n_________________________________________________________________\nlstm (LSTM)                  (None, 50, 128)           91648     \n_________________________________________________________________\ndropout (Dropout)            (None, 50, 128)           0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 128)               131584    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense (Dense)                (None, 5)                 645       \n_________________________________________________________________\nactivation (Activation)      (None, 5)                 0         \n=================================================================\nTotal params: 20,223,927\nTrainable params: 223,877\nNon-trainable params: 20,000,050\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commentary((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model compile......\n"
     ]
    }
   ],
   "source": [
    "print(\"Model compile......\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in X_train:\n",
    "#     print(len(x))\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model fit......\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3138 - accuracy: 0.4255\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1839 - accuracy: 0.4696\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1621 - accuracy: 0.4696\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1191 - accuracy: 0.4982\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0950 - accuracy: 0.4930\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0663 - accuracy: 0.5282\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0398 - accuracy: 0.5360\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0237 - accuracy: 0.5373\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9890 - accuracy: 0.5549\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9741 - accuracy: 0.5747\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9528 - accuracy: 0.5879\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9393 - accuracy: 0.5902\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9297 - accuracy: 0.5962\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.9009 - accuracy: 0.6128\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8777 - accuracy: 0.6214\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8597 - accuracy: 0.6263\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8357 - accuracy: 0.6494\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8029 - accuracy: 0.6628\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7791 - accuracy: 0.6777\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7412 - accuracy: 0.6912\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7196 - accuracy: 0.7021\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.7346 - accuracy: 0.6930\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6724 - accuracy: 0.7197\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6533 - accuracy: 0.7344\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.6200 - accuracy: 0.7542\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5929 - accuracy: 0.7622\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5684 - accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5486 - accuracy: 0.7860\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.5102 - accuracy: 0.8022\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4829 - accuracy: 0.8133\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.8385\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4465 - accuracy: 0.8356\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.8372\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3856 - accuracy: 0.8605\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.8791\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.3739 - accuracy: 0.8665\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3082 - accuracy: 0.8936\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2814 - accuracy: 0.9028\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2857 - accuracy: 0.9002\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2509 - accuracy: 0.9220\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2703 - accuracy: 0.9106\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2609 - accuracy: 0.9119\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2013 - accuracy: 0.9347\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2131 - accuracy: 0.9318\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9429\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1905 - accuracy: 0.9398\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1729 - accuracy: 0.9460\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.2266 - accuracy: 0.9300\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1685 - accuracy: 0.9429\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9546\n",
      "End of fitting......\n"
     ]
    }
   ],
   "source": [
    "print(\"Model fit......\")\n",
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 64, shuffle=True)\n",
    "print(\"End of fitting......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3917 - accuracy: 0.4844\n",
      "\n",
      "Test accuracy =  0.484375\n"
     ]
    }
   ],
   "source": [
    "X_valid_indices = sentences_to_indices(X_valid, word_to_index, max_len = maxLen)\n",
    "loss, acc = model.evaluate(X_valid_indices, Y_valid_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "family run personal nice area , older hotel basic 1 night stay , result having stop singapore way locations traveling stayed south east asia hotel 1 stays hotel bencoolen review property stay \n🧡🧡🧡🧡🧡 =/= 💚💚💚\nhome florence arrived long car trip angela awaiting , immediately showed room gave quick thorough instructions , able relax spacious cozy spotless room no delay , later directed neighborhood restaurant captured soul tuscany , did not use car stay minibus takes ponte vecchio block hotel gets minutes \n🧡 =/= 💚💚💚💚💚\ngorgeous resort beautiful , grounds amazing , complaint not best single travelers inclusive n ' t area singles , small casino resort open night , bars , beach pools nice , staff moderately friendly helpful not overly ,  \n🧡🧡 =/= 💚💚💚💚💚\njust like dumb blonde , wife stayed ocean royal service suite april 21 28th \n🧡🧡🧡🧡🧡 =/= 💚💚\nspecial celebration husband adult children just got week , stayed thanksgiving weekend celebrate 50th birthday , resort gorgeous , no roaches place clean , no problems check-in service safe did not work , arrived , security came immediately fixed , food ok \n🧡 =/= 💚💚💚💚\nnot expected , stayed ocean blue golf beach resort feb \n🧡🧡🧡🧡 =/= 💚💚\nperfect clean friendly helpful staff decent breakfast comfy bed cant fault hotel quite picky ,  \n🧡🧡🧡 =/= 💚💚💚💚💚\nloved did n ' t use bug spray , loved resort , suite lovely lay bed look ocean sit patio plunge pool relax , taken hint insect repellent room spray closet biting insects vicious , tend mosquito magnet multiple bites did not spray thoroughly repeatedly day evening \n🧡🧡 =/= 💚💚💚💚\ntotally worth price line short distance silver line makes totally worth cheaper price hotel , forget previous babies posted , unless trouble walking perfect , homework subway ahead time time , spend 15 airport weekly pass staying days , totally worth plus convenience factor \n🧡🧡 =/= 💚💚💚💚\njust okay stayed hotel convention , live boston thought fun stay hotel , good news , bed extremely comfortable , flat tv nice , loved contemporary decor room , nice city / water view \n🧡🧡🧡🧡 =/= 💚💚\nlousy desk service stayed friend biz trip 2 nites 21-23 april \n🧡🧡🧡🧡 =/= 💚\nfeel renewed husband just returned 7 night stay renew hotel \n🧡🧡🧡 =/= 💚💚💚💚💚\nnice unique simple staff friendly did accommodate , location perfect close beach food , really like borrow beach equipment free \n🧡🧡🧡 =/= 💚💚💚💚💚\ndont waste money , boyfriend thought picked maybe best hotels dallas stay 21st birthday night sadly wrong \n🧡🧡🧡🧡🧡 =/= 💚\ndisappointing booked hotel based reviews read disappointed , booked superior rooms paying price , couple given room just big house double bed , single travelling companion given single room feet square floor space shower flooded room used \n🧡🧡🧡 =/= 💚\nnot typical amsterdam hotel real hotel amsterdam city centre , really impressed , previous reviews say , complaint walk 10 mins station catch tram hit cafes bars , little immediate area access city centre obstructed railway ,  \n🧡🧡🧡 =/= 💚💚💚💚💚\nanniversary memorable wife celebrated 15th wedding anniversary blue moon hotel lower east new york city june 19th 2008 \n🧡🧡🧡 =/= 💚💚💚💚💚\nlittle gem great location , looking good hotel 100 euros night downtown barcelona , terrific location quiet local area brisk 20 min walk plaza catalunya \n🧡🧡🧡 =/= 💚💚💚💚💚\nnot centre not far worth walk , absolutely no complaints hotel , receptionists helpful rooms clean included free minibar good facilities excellent value money rate paid room night , breakfast extra 3 \n🧡🧡🧡 =/= 💚💚💚💚💚\nca n ' t wait , unhappy vacationers , background husband late 20 early 30 travel possible no kids hampton roads virginia , stayed riu yucatan mexican riveria familiar riu chain \n🧡 =/= 💚💚💚💚\nmiss match =  20 / 256\none star difference =  93 / 256\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "miss_match = 0\n",
    "one_difference = 0\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(abs(num - Y_test[i]) >= 2):\n",
    "        print(X_test[i])\n",
    "        print(emoji.emojize(':orange_heart:')*(num+1), '=/=',emoji.emojize(':green_heart:')*(Y_test[i]+1))\n",
    "        miss_match = miss_match +1\n",
    "    elif abs(num - Y_test[i]) == 1:\n",
    "        one_difference +=1\n",
    "print('miss match = ' , miss_match,  \"/\" , len(X_test))\n",
    "print('one star difference = ' , one_difference,  \"/\" , len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "miss match =  20 / 256 ===> 7.8125 %\none star difference =  93 / 256 ===> 36.328125 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('miss match = ' , miss_match,  \"/\" , len(X_test), '===>', (miss_match/len(X_test)*100), \"%\")\n",
    "print('one star difference = ' , one_difference,  \"/\" , len(X_test), '===>', (one_difference/len(X_test)*100), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}